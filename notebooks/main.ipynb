{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# BGH Gender Counterfactuals - Main Data Pipeline\n# This notebook orchestrates the complete data processing pipeline for creating\n# the BGH Gender Counterfactuals dataset from raw legal documents\n\n# Import project configuration settings\nfrom src.common import config",
   "id": "9d87ad8d39a455b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Scraping",
   "id": "2edeca1980f1f87c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Import scraping module for data collection from BGH (Federal Court of Justice) website\nimport src.scraping as scr",
   "id": "311bf4e9f65d153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": "# Step 1: Scrape document IDs from BGH website\n# This identifies all available civil appeals cases for download\n_ = await scr.scrape_ids()",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Step 2: Download the actual legal documents\n# Downloads PDF files for each identified case from the BGH website\nawait scr.download_docs()",
   "id": "19d760976e241c94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Step 3: Extract text content from PDF documents\n# Converts PDF files to machine-readable text for further processing\n_ = scr.extract_text()",
   "id": "f4aa429b58bd1c20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Step 4: Parse documents into structured format\n# Extracts key components (facts, legal reasoning, decisions) from raw text\n_ = scr.parse_docs()",
   "id": "24575787e899f0d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Labeling",
   "id": "8fe35bf1d9d56927"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Import labeling module for automated case classification\nfrom src.labeling import label_docs",
   "id": "e878ca071bc131a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Automatically label legal documents with case outcomes\n# Uses LLM to classify decisions as \"upheld\" or \"reversed\" based on case content\n_ = await label_docs()",
   "id": "bab1f2c0b0dd179b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Augmentation",
   "id": "de2b5bf2cf55d2dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Import augmentation module for creating gender counterfactuals\nfrom src.augmentation import create_augmentations",
   "id": "9995257d6a424e33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Generate gender-swapped versions of legal case facts\n# Creates counterfactual versions by swapping gender-specific language\n# This enables bias detection by comparing model predictions on original vs. swapped versions\n_ = await create_augmentations()",
   "id": "f59c9d69cf144fda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Train and Test Sets",
   "id": "841c19bc60afe14c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Import libraries for dataset creation and train/test splitting\nimport pandas as pd  # Data manipulation\nfrom sklearn.model_selection import train_test_split  # Stratified data splitting\nfrom datasets import Dataset, DatasetDict  # HuggingFace dataset format",
   "id": "3c3e58727139fd35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Load the augmented dataset with both original and gender-swapped case facts\n# Sort by ID to ensure consistent ordering across runs\ndf = pd.read_json(config.DOCS_AUGMENTED_JSONL, lines=True).sort_values(by=\"id\")",
   "id": "d7f9e71604a15e1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Create initial train/test split (2/3 train, 1/3 test)\n# Use stratified split to maintain class balance in both sets\n# Fixed random state ensures reproducible splits\ntrain_unbalanced, test = train_test_split(\n    df,\n    test_size=1/3,\n    stratify=df.decision,  # Maintain proportion of \"upheld\" vs \"reversed\" decisions\n    random_state=42,\n    shuffle=True\n)",
   "id": "39139d6874b6cf73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Balance the training set by undersampling the majority class\n# This ensures equal representation of \"upheld\" and \"reversed\" decisions in training\nn = train_unbalanced.decision.value_counts().min()  # Get size of minority class\ntrain = (\n    train_unbalanced.groupby(\"decision\")  # Group by decision type\n    .sample(n=n, random_state=42)        # Sample n cases from each group\n    .sample(frac=1, random_state=42)     # Shuffle the final balanced dataset\n)",
   "id": "889b49912e5792db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Reset indices for clean, sequential indexing in final datasets\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)",
   "id": "e6b1d9a8f2bd752",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Convert pandas DataFrames to HuggingFace Dataset format\n# This format is optimized for machine learning workflows and model training\ntrain_dataset = Dataset.from_pandas(train)\ntest_dataset = Dataset.from_pandas(test)\n\n# Combine into a DatasetDict for easy access to both splits\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"test\": test_dataset\n})",
   "id": "23c83e1ab83fe50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Save the final dataset to disk in HuggingFace format\n# This creates the \"BGH-CivAppeals-GenderCF\" dataset ready for upload and use\ndataset.save_to_disk(\n    config.DATA_DIR / \"BGH-CivAppeals-GenderCF\"\n)",
   "id": "66cc7f09d97fa4d8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}